{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "botuWlUNNfGU"
      },
      "outputs": [],
      "source": [
        "# Set seeds for reproducibility\n",
        "import random\n",
        "random.seed(0)\n",
        "\n",
        "import numpy as np\n",
        "np.random.seed(0)\n",
        "\n",
        "import tensorflow as tf\n",
        "tf.random.set_seed(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "049aCSeUNpoV"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import numpy as np\n",
        "import time\n",
        "import json\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "import wandb\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxMEApdXNpk9",
        "outputId": "1fe86bbe-f0fb-4a96-b825-f7f8380e5739"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.12/dist-packages (1.7.4.5)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.12/dist-packages (from kaggle) (6.3.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2025.11.12)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from kaggle) (3.4.4)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from kaggle) (3.11)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from kaggle) (5.29.5)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.9.0.post0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.12/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.32.4)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from kaggle) (75.2.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.12/dist-packages (from kaggle) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.12/dist-packages (from kaggle) (1.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from kaggle) (4.67.1)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.5.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from kaggle) (0.5.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "DTAcn8lRNpiR"
      },
      "outputs": [],
      "source": [
        "kaggle_credentails = json.load(open(\"kaggle.json\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "_0diCbDANpfd"
      },
      "outputs": [],
      "source": [
        "# setup Kaggle API key as environment variables\n",
        "os.environ['KAGGLE_USERNAME'] = kaggle_credentails[\"username\"]\n",
        "os.environ['KAGGLE_KEY'] = kaggle_credentails[\"key\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zv_3jUw0NpYC",
        "outputId": "26413108-8a3d-4a99-c0ab-0761a43dbcbd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/vipoooool/new-plant-diseases-dataset\n",
            "License(s): copyright-authors\n",
            "Downloading new-plant-diseases-dataset.zip to /content\n",
            " 97% 2.60G/2.70G [00:19<00:02, 40.2MB/s]\n",
            "100% 2.70G/2.70G [00:20<00:00, 144MB/s] \n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download -d vipoooool/new-plant-diseases-dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "YA1tV1dpNyWk"
      },
      "outputs": [],
      "source": [
        "from zipfile import ZipFile\n",
        "\n",
        "# Unzip the downloaded dataset\n",
        "with ZipFile(\"new-plant-diseases-dataset.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v0gZj2IDNyTN",
        "outputId": "73852d2e-54cb-4b68-89a9-1718a49b98ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset prepared.\n"
          ]
        }
      ],
      "source": [
        "# Create base folders\n",
        "!mkdir -p /content/newData/train\n",
        "!mkdir -p /content/newData/valid\n",
        "\n",
        "# Dataset original path\n",
        "DATASET=\"/content/new plant diseases dataset(augmented)/New Plant Diseases Dataset(Augmented)\"\n",
        "\n",
        "# Copy the 4 grape classes for training\n",
        "!cp -r \"$DATASET/train/Grape___Black_rot\" /content/newData/train\n",
        "!cp -r \"$DATASET/train/Grape___Esca_(Black_Measles)\" /content/newData/train\n",
        "!cp -r \"$DATASET/train/Grape___Leaf_blight_(Isariopsis_Leaf_Spot)\" /content/newData/train\n",
        "!cp -r \"$DATASET/train/Grape___healthy\" /content/newData/train\n",
        "\n",
        "# Copy the 4 grape classes for validation\n",
        "!cp -r \"$DATASET/valid/Grape___Black_rot\" /content/newData/valid\n",
        "!cp -r \"$DATASET/valid/Grape___Esca_(Black_Measles)\" /content/newData/valid\n",
        "!cp -r \"$DATASET/valid/Grape___Leaf_blight_(Isariopsis_Leaf_Spot)\" /content/newData/valid\n",
        "!cp -r \"$DATASET/valid/Grape___healthy\" /content/newData/valid\n",
        "\n",
        "# Create split folders\n",
        "!mkdir -p /content/newData/train_split\n",
        "!mkdir -p /content/newData/valid_split\n",
        "!mkdir -p /content/newData/test_split\n",
        "\n",
        "print(\"Dataset prepared.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "8ol0hIw5NyQf"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import numpy as np\n",
        "\n",
        "# Define source and destination directories (COLAB VERSION)\n",
        "source_train_dir = '/content/newData/train'\n",
        "source_valid_dir = '/content/newData/valid'\n",
        "target_train_dir = '/content/newData/train_split'\n",
        "target_valid_dir = '/content/newData/valid_split'\n",
        "target_test_dir = '/content/newData/test_split'\n",
        "\n",
        "# Create target directories for each class\n",
        "for class_name in os.listdir(source_train_dir):\n",
        "    os.makedirs(os.path.join(target_train_dir, class_name), exist_ok=True)\n",
        "    os.makedirs(os.path.join(target_valid_dir, class_name), exist_ok=True)\n",
        "    os.makedirs(os.path.join(target_test_dir, class_name), exist_ok=True)\n",
        "\n",
        "    # Get file paths\n",
        "    class_source_path = os.path.join(source_train_dir, class_name)\n",
        "    files = os.listdir(class_source_path)\n",
        "\n",
        "    # Shuffle and split files\n",
        "    np.random.shuffle(files)\n",
        "    num_files = len(files)\n",
        "\n",
        "    train_end = int(0.8 * num_files)\n",
        "    valid_end = train_end + int(0.1 * num_files)\n",
        "\n",
        "    train_files = files[:train_end]\n",
        "    valid_files = files[train_end:valid_end]\n",
        "    test_files = files[valid_end:]\n",
        "\n",
        "    # Copy files to respective directories\n",
        "    for file in train_files:\n",
        "        shutil.copy(os.path.join(class_source_path, file), os.path.join(target_train_dir, class_name, file))\n",
        "    for file in valid_files:\n",
        "        shutil.copy(os.path.join(class_source_path, file), os.path.join(target_valid_dir, class_name, file))\n",
        "    for file in test_files:\n",
        "        shutil.copy(os.path.join(class_source_path, file), os.path.join(target_test_dir, class_name, file))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ulLFcmX4NyOC",
        "outputId": "c07405c0-e331-45b7-909b-a33b0d8c7bf2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training counts: {'Grape___Black_rot': 1510, 'Grape___Esca_(Black_Measles)': 1536, 'Grape___Leaf_blight_(Isariopsis_Leaf_Spot)': 1377, 'Grape___healthy': 1353}\n",
            "Validation counts: {'Grape___Black_rot': 188, 'Grape___Esca_(Black_Measles)': 192, 'Grape___Leaf_blight_(Isariopsis_Leaf_Spot)': 172, 'Grape___healthy': 169}\n",
            "Test counts: {'Grape___Black_rot': 190, 'Grape___Esca_(Black_Measles)': 192, 'Grape___Leaf_blight_(Isariopsis_Leaf_Spot)': 173, 'Grape___healthy': 170}\n"
          ]
        }
      ],
      "source": [
        "# Define the directories (COLAB VERSION)\n",
        "train_dir = '/content/newData/train_split'\n",
        "valid_dir = '/content/newData/valid_split'\n",
        "test_dir = '/content/newData/test_split'\n",
        "\n",
        "# Function to count files in each class folder\n",
        "def count_files_in_directory(directory):\n",
        "    class_counts = {}\n",
        "    for class_name in os.listdir(directory):\n",
        "        class_path = os.path.join(directory, class_name)\n",
        "        if os.path.isdir(class_path):  # Ensure it's a directory\n",
        "            class_counts[class_name] = len(os.listdir(class_path))\n",
        "    return class_counts\n",
        "\n",
        "# Get counts for train, valid, and test directories\n",
        "train_counts = count_files_in_directory(train_dir)\n",
        "valid_counts = count_files_in_directory(valid_dir)\n",
        "test_counts = count_files_in_directory(test_dir)\n",
        "\n",
        "# Print the counts\n",
        "print(\"Training counts:\", train_counts)\n",
        "print(\"Validation counts:\", valid_counts)\n",
        "print(\"Test counts:\", test_counts)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "id": "u9qOOE3RN-bv",
        "outputId": "2c4a49a5-898c-45da-8e04-a57558debc68"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33masma-daaab\u001b[0m (\u001b[33mtesnime328-tek-up\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.23.0"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251125_225337-a71lqmcp</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/tesnime328-tek-up/plantdoctor/runs/a71lqmcp' target=\"_blank\">cnn_again_part7</a></strong> to <a href='https://wandb.ai/tesnime328-tek-up/plantdoctor' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/tesnime328-tek-up/plantdoctor' target=\"_blank\">https://wandb.ai/tesnime328-tek-up/plantdoctor</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/tesnime328-tek-up/plantdoctor/runs/a71lqmcp' target=\"_blank\">https://wandb.ai/tesnime328-tek-up/plantdoctor/runs/a71lqmcp</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "use_wandb = True\n",
        "import wandb\n",
        "from wandb.integration.keras import WandbMetricsLogger, WandbModelCheckpoint\n",
        "\n",
        "if use_wandb:\n",
        "    import wandb\n",
        "    wandb.init(project=\"plantdoctor\", name=\"cnn_again_part7\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-yoQ_X6N-YZ",
        "outputId": "354bddfe-a738-4e28-bfae-e647a0a25d97"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 5776 images belonging to 4 classes.\n",
            "Found 721 images belonging to 4 classes.\n",
            "Found 725 images belonging to 4 classes.\n"
          ]
        }
      ],
      "source": [
        "# Data Preparation with ImageDataGenerator\n",
        "batch_size = 32\n",
        "img_size = (224, 224)\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=30,\n",
        "    zoom_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# === FIXED PATHS FOR COLAB ===\n",
        "train_dir = \"/content/newData/train_split\"\n",
        "valid_dir = \"/content/newData/valid_split\"\n",
        "test_dir = \"/content/newData/test_split\"\n",
        "\n",
        "# Train sets\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "validation_generator = valid_datagen.flow_from_directory(\n",
        "    valid_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# Test set\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2cxv5uAIN-V6",
        "outputId": "69a0c5ec-99fb-4067-ea85-a6b42d82052f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/11\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 453ms/step - accuracy: 0.3868 - loss: 1.2130 - precision: 0.6066 - recall: 0.1139 - val_accuracy: 0.6186 - val_loss: 0.8512 - val_precision: 0.6866 - val_recall: 0.5409\n",
            "Epoch 2/11\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 408ms/step - accuracy: 0.7462 - loss: 0.6138 - precision: 0.7963 - recall: 0.6597 - val_accuracy: 0.6283 - val_loss: 0.9939 - val_precision: 0.6479 - val_recall: 0.6075\n",
            "Epoch 3/11\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 406ms/step - accuracy: 0.7990 - loss: 0.5052 - precision: 0.8244 - recall: 0.7681 - val_accuracy: 0.6907 - val_loss: 0.8894 - val_precision: 0.7118 - val_recall: 0.6782\n",
            "Epoch 4/11\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 408ms/step - accuracy: 0.8292 - loss: 0.4433 - precision: 0.8486 - recall: 0.8061 - val_accuracy: 0.7767 - val_loss: 0.5661 - val_precision: 0.8027 - val_recall: 0.7503\n",
            "Epoch 5/11\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 428ms/step - accuracy: 0.8537 - loss: 0.3865 - precision: 0.8682 - recall: 0.8408 - val_accuracy: 0.7517 - val_loss: 0.7169 - val_precision: 0.7718 - val_recall: 0.7365\n",
            "Epoch 6/11\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 415ms/step - accuracy: 0.8782 - loss: 0.3192 - precision: 0.8867 - recall: 0.8707 - val_accuracy: 0.7351 - val_loss: 0.7819 - val_precision: 0.7463 - val_recall: 0.7060\n",
            "Epoch 7/11\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 419ms/step - accuracy: 0.8820 - loss: 0.3008 - precision: 0.8932 - recall: 0.8712 - val_accuracy: 0.7642 - val_loss: 0.7071 - val_precision: 0.7858 - val_recall: 0.7531\n",
            "Epoch 8/11\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 405ms/step - accuracy: 0.9088 - loss: 0.2634 - precision: 0.9160 - recall: 0.8965 - val_accuracy: 0.8752 - val_loss: 0.3382 - val_precision: 0.8862 - val_recall: 0.8641\n",
            "Epoch 9/11\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 404ms/step - accuracy: 0.9124 - loss: 0.2423 - precision: 0.9193 - recall: 0.9057 - val_accuracy: 0.7614 - val_loss: 0.6826 - val_precision: 0.7829 - val_recall: 0.7503\n",
            "Epoch 10/11\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 419ms/step - accuracy: 0.9077 - loss: 0.2530 - precision: 0.9184 - recall: 0.8979 - val_accuracy: 0.8904 - val_loss: 0.2907 - val_precision: 0.9007 - val_recall: 0.8807\n",
            "Epoch 11/11\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 398ms/step - accuracy: 0.9234 - loss: 0.2092 - precision: 0.9315 - recall: 0.9170 - val_accuracy: 0.7933 - val_loss: 0.6146 - val_precision: 0.8069 - val_recall: 0.7822\n"
          ]
        }
      ],
      "source": [
        "# Build the optimized CNN model\n",
        "def create_optimized_cnn(num_classes):\n",
        "    model = models.Sequential([\n",
        "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=img_size + (3,)),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        layers.GlobalAveragePooling2D(),\n",
        "        layers.Dense(256, activation='relu'),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Create the model\n",
        "model = create_optimized_cnn(train_generator.num_classes)\n",
        "\n",
        "# Compile the model with learning rate scheduling\n",
        "lr_schedule = optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate=1e-3,\n",
        "    decay_steps=10000,\n",
        "    decay_rate=0.9\n",
        ")\n",
        "optimizer = optimizers.Adam(learning_rate=lr_schedule)\n",
        "\n",
        "model.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()]\n",
        ")\n",
        "\n",
        "# Callbacks\n",
        "early_stop = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=5,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "checkpoint = ModelCheckpoint(\n",
        "    'cnn_model.keras',\n",
        "    monitor='val_loss',\n",
        "    save_best_only=True\n",
        ")\n",
        "\n",
        "# === ADD W&B CALLBACKS WITHOUT CHANGING YOUR CODE ===\n",
        "callbacks_list = [early_stop, checkpoint]\n",
        "if use_wandb:\n",
        "    callbacks_list.append(WandbMetricsLogger())\n",
        "    callbacks_list.append(WandbModelCheckpoint(\"model-wandb.keras\"))\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=validation_generator,\n",
        "    epochs=11,\n",
        "    callbacks=callbacks_list\n",
        ")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
